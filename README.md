# Embodied Spatial Reasoning

This project explores embodied spatial reasoning using simulated environments.
A camera-equipped agent navigates 3D scenes, generating egocentric observations
that can later be consumed by vision-language models for reasoning.

Current stage:
- Habitat-Sim based environment
- Scripted camera embodiment
- Sequential frame generation
- Spatial trajectories

Future directions:
- Policy-driven exploration
- Spatial memory
- Vision-language reasoning
